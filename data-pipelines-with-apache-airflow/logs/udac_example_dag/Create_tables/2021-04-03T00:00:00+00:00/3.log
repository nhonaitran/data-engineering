[2021-04-06 03:04:28,656] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: udac_example_dag.Create_tables 2021-04-03T00:00:00+00:00 [queued]>
[2021-04-06 03:04:28,716] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: udac_example_dag.Create_tables 2021-04-03T00:00:00+00:00 [queued]>
[2021-04-06 03:04:28,717] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2021-04-06 03:04:28,719] {taskinstance.py:1043} INFO - Starting attempt 3 of 4
[2021-04-06 03:04:28,721] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2021-04-06 03:04:28,766] {taskinstance.py:1063} INFO - Executing <Task(CreateTablesOperator): Create_tables> on 2021-04-03T00:00:00+00:00
[2021-04-06 03:04:28,775] {standard_task_runner.py:52} INFO - Started process 105 to run task
[2021-04-06 03:04:28,824] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'udac_example_dag', 'Create_tables', '2021-04-03T00:00:00+00:00', '--job-id', '28', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/udac_example_dag.py', '--cfg-path', '/tmp/tmperlzwcrj', '--error-file', '/tmp/tmpcklppeei']
[2021-04-06 03:04:28,833] {standard_task_runner.py:77} INFO - Job 28: Subtask Create_tables
[2021-04-06 03:04:29,154] {logging_mixin.py:104} INFO - Running <TaskInstance: udac_example_dag.Create_tables 2021-04-03T00:00:00+00:00 [running]> on host 0ccaa9d2b3f1
[2021-04-06 03:04:29,652] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=udacity
AIRFLOW_CTX_DAG_ID=udac_example_dag
AIRFLOW_CTX_TASK_ID=Create_tables
AIRFLOW_CTX_EXECUTION_DATE=2021-04-03T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-04-03T00:00:00+00:00
[2021-04-06 03:04:29,665] {create_tables.py:21} INFO - Creating all tables in schema:
[2021-04-06 03:04:29,808] {base.py:74} INFO - Using connection to: id: redshift. Host: sparkify-redshift.c5c7ovgg2wrr.us-west-2.redshift.amazonaws.com, Port: 5439, Schema: sparkify-song-analytics, Login: data.engineer, Password: XXXXXXXX, extra: None
[2021-04-06 03:04:31,152] {dbapi.py:180} INFO - Running statement: 
        BEGIN;
        DROP TABLE IF EXISTS staging_events;
        CREATE TABLE staging_events (
            artist varchar(256),
            auth varchar(256),
            firstname varchar(256),
            gender varchar(256),
            iteminsession int4,
            lastname varchar(256),
            length numeric(18,0),
            "level" varchar(256),
            location varchar(256),
            "method" varchar(256),
            page varchar(256),
            registration numeric(18,0),
            sessionid int4,
            song varchar(256),
            status int4,
            ts int8,
            useragent varchar(256),
            userid int4
        );
        COMMIT;
    , parameters: None
[2021-04-06 03:04:31,469] {dbapi.py:186} INFO - Rows affected: -1
[2021-04-06 03:04:31,744] {base.py:74} INFO - Using connection to: id: redshift. Host: sparkify-redshift.c5c7ovgg2wrr.us-west-2.redshift.amazonaws.com, Port: 5439, Schema: sparkify-song-analytics, Login: data.engineer, Password: XXXXXXXX, extra: None
[2021-04-06 03:04:32,476] {dbapi.py:180} INFO - Running statement: 
        BEGIN;
        DROP TABLE IF EXISTS staging_songs;
        CREATE TABLE staging_songs (
            num_songs int4,
            artist_id varchar(256),
            artist_name varchar(256),
            artist_latitude numeric(18,0),
            artist_longitude numeric(18,0),
            artist_location varchar(256),
            song_id varchar(256),
            title varchar(256),
            duration numeric(18,0),
            "year" int4
        );
        COMMIT;
    , parameters: None
[2021-04-06 03:04:32,767] {dbapi.py:186} INFO - Rows affected: -1
[2021-04-06 03:04:32,871] {base.py:74} INFO - Using connection to: id: redshift. Host: sparkify-redshift.c5c7ovgg2wrr.us-west-2.redshift.amazonaws.com, Port: 5439, Schema: sparkify-song-analytics, Login: data.engineer, Password: XXXXXXXX, extra: None
[2021-04-06 03:04:33,442] {dbapi.py:180} INFO - Running statement: 
        BEGIN;
        DROP TABLE IF EXISTS songplays;
        CREATE TABLE IF NOT EXISTS songplays (
            playid varchar(32) NOT NULL,
            start_time timestamp NOT NULL,
            userid int4 NOT NULL,
            "level" varchar(256),
            songid varchar(256),
            artistid varchar(256),
            sessionid int4,
            location varchar(256),
            user_agent varchar(256),
            CONSTRAINT songplays_pkey PRIMARY KEY (playid)
        );
        COMMIT;
    , parameters: None
[2021-04-06 03:04:33,718] {dbapi.py:186} INFO - Rows affected: -1
[2021-04-06 03:04:33,812] {base.py:74} INFO - Using connection to: id: redshift. Host: sparkify-redshift.c5c7ovgg2wrr.us-west-2.redshift.amazonaws.com, Port: 5439, Schema: sparkify-song-analytics, Login: data.engineer, Password: XXXXXXXX, extra: None
[2021-04-06 03:04:34,404] {dbapi.py:180} INFO - Running statement: 
        BEGIN;
        DROP TABLE IF EXISTS users;
        CREATE TABLE IF NOT EXISTS users (
            userid int4 NOT NULL,
            first_name varchar(256),
            last_name varchar(256),
            gender varchar(256),
            "level" varchar(256),
            CONSTRAINT users_pkey PRIMARY KEY (userid)
        );
        COMMIT;
    , parameters: None
[2021-04-06 03:04:34,682] {dbapi.py:186} INFO - Rows affected: -1
[2021-04-06 03:04:34,785] {base.py:74} INFO - Using connection to: id: redshift. Host: sparkify-redshift.c5c7ovgg2wrr.us-west-2.redshift.amazonaws.com, Port: 5439, Schema: sparkify-song-analytics, Login: data.engineer, Password: XXXXXXXX, extra: None
[2021-04-06 03:04:35,377] {dbapi.py:180} INFO - Running statement: 
        BEGIN;
        DROP TABLE IF EXISTS songs;
        CREATE TABLE IF NOT EXISTS songs (
            songid varchar(256) NOT NULL,
            title varchar(256),
            artistid varchar(256),
            "year" int4,
            duration numeric(18,0),
            CONSTRAINT songs_pkey PRIMARY KEY (songid)
        );
        COMMIT;
    , parameters: None
[2021-04-06 03:04:35,659] {dbapi.py:186} INFO - Rows affected: -1
[2021-04-06 03:04:35,753] {base.py:74} INFO - Using connection to: id: redshift. Host: sparkify-redshift.c5c7ovgg2wrr.us-west-2.redshift.amazonaws.com, Port: 5439, Schema: sparkify-song-analytics, Login: data.engineer, Password: XXXXXXXX, extra: None
[2021-04-06 03:04:36,352] {dbapi.py:180} INFO - Running statement: 
        BEGIN;
        DROP TABLE IF EXISTS artists;
        CREATE TABLE IF NOT EXISTS artists (
            artistid varchar(256) NOT NULL,
            name varchar(256),
            location varchar(256),
            latitude numeric(18,0),
            longitude numeric(18,0)
        );
        COMMIT;
    , parameters: None
[2021-04-06 03:04:36,646] {dbapi.py:186} INFO - Rows affected: -1
[2021-04-06 03:04:36,742] {base.py:74} INFO - Using connection to: id: redshift. Host: sparkify-redshift.c5c7ovgg2wrr.us-west-2.redshift.amazonaws.com, Port: 5439, Schema: sparkify-song-analytics, Login: data.engineer, Password: XXXXXXXX, extra: None
[2021-04-06 03:04:37,337] {dbapi.py:180} INFO - Running statement: 
        BEGIN;
        DROP TABLE IF EXISTS timeplays;
        CREATE TABLE IF NOT EXISTS timeplays (
            start_time timestamp NOT NULL,
            "hour" int4,
            "day" int4,
            week int4,
            "month" varchar(256),
            "year" int4,
            weekday varchar(256),
            CONSTRAINT time_pkey PRIMARY KEY (start_time)
        );
        COMMIT;
    , parameters: None
[2021-04-06 03:04:37,665] {dbapi.py:186} INFO - Rows affected: -1
[2021-04-06 03:04:37,772] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=udac_example_dag, task_id=Create_tables, execution_date=20210403T000000, start_date=20210406T030428, end_date=20210406T030437
[2021-04-06 03:04:37,813] {taskinstance.py:1220} INFO - 2 downstream tasks scheduled from follow-on schedule check
[2021-04-06 03:04:37,836] {local_task_job.py:146} INFO - Task exited with return code 0
