[2021-04-06 03:09:35,159] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: udac_example_dag.Create_tables 2021-03-31T00:00:00+00:00 [queued]>
[2021-04-06 03:09:35,191] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: udac_example_dag.Create_tables 2021-03-31T00:00:00+00:00 [queued]>
[2021-04-06 03:09:35,194] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2021-04-06 03:09:35,195] {taskinstance.py:1043} INFO - Starting attempt 4 of 4
[2021-04-06 03:09:35,197] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2021-04-06 03:09:35,229] {taskinstance.py:1063} INFO - Executing <Task(CreateTablesOperator): Create_tables> on 2021-03-31T00:00:00+00:00
[2021-04-06 03:09:35,245] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'udac_example_dag', 'Create_tables', '2021-03-31T00:00:00+00:00', '--job-id', '71', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/udac_example_dag.py', '--cfg-path', '/tmp/tmpt3xay56e', '--error-file', '/tmp/tmpjjtog7dw']
[2021-04-06 03:09:35,247] {standard_task_runner.py:77} INFO - Job 71: Subtask Create_tables
[2021-04-06 03:09:35,240] {standard_task_runner.py:52} INFO - Started process 179 to run task
[2021-04-06 03:09:35,319] {logging_mixin.py:104} INFO - Running <TaskInstance: udac_example_dag.Create_tables 2021-03-31T00:00:00+00:00 [running]> on host 0ccaa9d2b3f1
[2021-04-06 03:09:35,366] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=udacity
AIRFLOW_CTX_DAG_ID=udac_example_dag
AIRFLOW_CTX_TASK_ID=Create_tables
AIRFLOW_CTX_EXECUTION_DATE=2021-03-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-03-31T00:00:00+00:00
[2021-04-06 03:09:35,368] {create_tables.py:21} INFO - Creating all tables in schema:
[2021-04-06 03:09:35,383] {base.py:74} INFO - Using connection to: id: redshift. Host: sparkify-redshift.c5c7ovgg2wrr.us-west-2.redshift.amazonaws.com, Port: 5439, Schema: sparkify-song-analytics, Login: data.engineer, Password: XXXXXXXX, extra: None
[2021-04-06 03:09:35,998] {dbapi.py:180} INFO - Running statement: 
        BEGIN;
        DROP TABLE IF EXISTS staging_events;
        CREATE TABLE staging_events (
            artist varchar(256),
            auth varchar(256),
            firstname varchar(256),
            gender varchar(256),
            iteminsession int4,
            lastname varchar(256),
            length numeric(18,0),
            "level" varchar(256),
            location varchar(256),
            "method" varchar(256),
            page varchar(256),
            registration numeric(18,0),
            sessionid int4,
            song varchar(256),
            status int4,
            ts int8,
            useragent varchar(256),
            userid int4
        );
        COMMIT;
    , parameters: None
[2021-04-06 03:09:36,399] {dbapi.py:186} INFO - Rows affected: -1
[2021-04-06 03:09:36,493] {base.py:74} INFO - Using connection to: id: redshift. Host: sparkify-redshift.c5c7ovgg2wrr.us-west-2.redshift.amazonaws.com, Port: 5439, Schema: sparkify-song-analytics, Login: data.engineer, Password: XXXXXXXX, extra: None
[2021-04-06 03:09:37,062] {dbapi.py:180} INFO - Running statement: 
        BEGIN;
        DROP TABLE IF EXISTS staging_songs;
        CREATE TABLE staging_songs (
            num_songs int4,
            artist_id varchar(256),
            artist_name varchar(256),
            artist_latitude numeric(18,0),
            artist_longitude numeric(18,0),
            artist_location varchar(256),
            song_id varchar(256),
            title varchar(256),
            duration numeric(18,0),
            "year" int4
        );
        COMMIT;
    , parameters: None
[2021-04-06 03:14:32,305] {taskinstance.py:1455} ERROR - could not open relation with OID 101589
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1112, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1285, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1315, in _execute_task
    result = task_copy.execute(context=context)
  File "/opt/airflow/plugins/operators/create_tables.py", line 22, in execute
    [redshift.run(create_table) for create_table in SqlQueries.create_table_queries]
  File "/opt/airflow/plugins/operators/create_tables.py", line 22, in <listcomp>
    [redshift.run(create_table) for create_table in SqlQueries.create_table_queries]
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/hooks/dbapi.py", line 184, in run
    cur.execute(sql_statement)
psycopg2.errors.InternalError_: could not open relation with OID 101589

[2021-04-06 03:14:32,314] {taskinstance.py:1503} INFO - Marking task as FAILED. dag_id=udac_example_dag, task_id=Create_tables, execution_date=20210331T000000, start_date=20210406T030935, end_date=20210406T031432
[2021-04-06 03:14:32,413] {local_task_job.py:146} INFO - Task exited with return code 1
