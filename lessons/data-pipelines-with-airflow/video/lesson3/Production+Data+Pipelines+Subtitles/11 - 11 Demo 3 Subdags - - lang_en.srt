1
00:00:00,000 --> 00:00:05,100
In this demo, we're going to create a DAG that uses a subDAG.

2
00:00:05,100 --> 00:00:09,915
You'll see how to populate a subDAG and instantiate it in your own DAGs.

3
00:00:09,915 --> 00:00:13,200
So, we're going to return to the homepage of Airflow,

4
00:00:13,200 --> 00:00:15,750
and then we're going to jump back to the code.

5
00:00:15,750 --> 00:00:21,090
First thing I'm going to do is I'm going to open the folder lesson3.demo3.

6
00:00:21,090 --> 00:00:24,990
I just want to stop for a moment and point out that in your exercise you will have

7
00:00:24,990 --> 00:00:28,920
an exercise3 folder, not an exercise3.py.

8
00:00:28,920 --> 00:00:32,325
So, expect to see a folder called exercise3.

9
00:00:32,325 --> 00:00:38,085
Then this folder, you're going to see two files: dag.py and subdag.py.

10
00:00:38,085 --> 00:00:40,410
Let's first look at our DAG.

11
00:00:40,410 --> 00:00:44,690
So, you'll see this DAG looks fairly standard so far.

12
00:00:44,690 --> 00:00:46,745
We have a DAG definition.

13
00:00:46,745 --> 00:00:52,325
But almost immediately, you'll see that we have something called a SubDagOperator,

14
00:00:52,325 --> 00:00:54,875
which is something that we haven't seen before.

15
00:00:54,875 --> 00:00:57,725
I'm going to show you how we created the subDAG in a moment,

16
00:00:57,725 --> 00:01:00,485
but I first wanted to show you how it gets used in the DAG.

17
00:01:00,485 --> 00:01:04,925
So, the first thing to point out here is that we've imported the SubDagOperator.

18
00:01:04,925 --> 00:01:06,910
You can see this on line five.

19
00:01:06,910 --> 00:01:11,465
So, a SubDagOperator is much like other operators we've talked about in this class,

20
00:01:11,465 --> 00:01:14,555
such as PostgresOperator or Python operator,

21
00:01:14,555 --> 00:01:17,705
but the important thing to keep in mind is that

22
00:01:17,705 --> 00:01:22,940
the SubDagOperator is actually calling a Python factory function.

23
00:01:22,940 --> 00:01:25,430
In the case of line 22,

24
00:01:25,430 --> 00:01:29,690
it's calling the get_s3_to_redshift_dag function to return a DAG.

25
00:01:29,690 --> 00:01:35,450
So, this operator is actually executing an entire DAG.

26
00:01:35,450 --> 00:01:38,580
We'll get into these arguments here in just a moment.

27
00:01:38,580 --> 00:01:40,340
For now, we can just ignore them.

28
00:01:40,340 --> 00:01:42,500
Let's go take a look at our subDAG.

29
00:01:42,500 --> 00:01:47,860
So, again, lesson3.demo3, we're going to open subdag.py.

30
00:01:47,860 --> 00:01:49,365
If this was your exercise,

31
00:01:49,365 --> 00:01:53,550
you would open lesson3.exercise3, subdag.py.

32
00:01:53,550 --> 00:01:56,645
In here, you're going to see a number of things to find

33
00:01:56,645 --> 00:01:59,665
that look somewhat familiar once we finish the demonstration.

34
00:01:59,665 --> 00:02:03,920
At this point, we've only defined a function that takes a number of arguments.

35
00:02:03,920 --> 00:02:07,670
This function get_s3_to_redshift_dag and returns it.

36
00:02:07,670 --> 00:02:11,485
So, you can see we have another DAG defined in here.

37
00:02:11,485 --> 00:02:13,725
So, even though this is a function,

38
00:02:13,725 --> 00:02:18,180
it is actually defining and returning a DAG.

39
00:02:18,610 --> 00:02:20,795
It's also worth mentioning,

40
00:02:20,795 --> 00:02:22,700
and this is very important that we have

41
00:02:22,700 --> 00:02:26,630
the DAG name defined as the parent_dag_name.task_id.

42
00:02:28,910 --> 00:02:33,270
You must name your subDAGs following this pattern.

43
00:02:33,270 --> 00:02:36,275
Airflow will actually throw an error if you don't follow this pattern.

44
00:02:36,275 --> 00:02:40,340
So, again, the name of your subDAGs must always be the name of

45
00:02:40,340 --> 00:02:48,130
the parent DAG dot the name of the new task ID.

46
00:02:48,170 --> 00:02:51,080
All right. So, now that we've done that,

47
00:02:51,080 --> 00:02:56,020
we're going to actually start to combine the functionality from our DAG into the subDAG.

48
00:02:56,020 --> 00:02:57,235
So, I'm going to open,

49
00:02:57,235 --> 00:02:58,660
I'm going to do a split window here.

50
00:02:58,660 --> 00:03:02,720
I'm going to open this DAG below so we can start moving the code around.

51
00:03:04,220 --> 00:03:08,155
So, on the top window here where I'm moving the cursor,

52
00:03:08,155 --> 00:03:09,475
this is our subDAG,

53
00:03:09,475 --> 00:03:13,880
and you can see that on the middle section here it says dags/lesson3/demo3/subdag.py.

54
00:03:14,490 --> 00:03:18,100
The bottom code, this is our Dag.

55
00:03:18,100 --> 00:03:22,210
We want to move some of the code from the this DAG into our subDAG.

56
00:03:22,210 --> 00:03:24,820
So, we're going to move down here,

57
00:03:24,820 --> 00:03:29,035
and we're going to move the create_table code into our subDAG.

58
00:03:29,035 --> 00:03:32,305
So, I'm going to just grab this,

59
00:03:32,305 --> 00:03:35,050
copy and create code,

60
00:03:35,050 --> 00:03:41,230
and I'm going to paste it in.

61
00:03:41,960 --> 00:03:46,069
Now, we're not done quite yet because this is specific,

62
00:03:46,069 --> 00:03:48,845
this code is specifically formatted for the trips_table.

63
00:03:48,845 --> 00:03:54,485
The whole point of a subDAG is that it's supposed to be reusable.

64
00:03:54,485 --> 00:03:58,180
So, if we wrote a subDAG that just works on trips_table,

65
00:03:58,180 --> 00:04:00,365
that really wouldn't be very useful.

66
00:04:00,365 --> 00:04:03,920
So, the first thing we need to do is go back and look at our arguments.

67
00:04:03,920 --> 00:04:07,280
Here, we'll notice that we have a table, we have our bucket,

68
00:04:07,280 --> 00:04:09,710
key, all of the arguments that we actually

69
00:04:09,710 --> 00:04:13,190
need to instantiate the operators this task uses.

70
00:04:13,190 --> 00:04:15,365
So, I'm going to scroll down here.

71
00:04:15,365 --> 00:04:17,345
We're going to go ahead and give this task_id,

72
00:04:17,345 --> 00:04:20,210
we're going to turn this into a formatter.

73
00:04:20,210 --> 00:04:28,210
So, we're going to use Python formatting to say, create_table argument table.

74
00:04:28,210 --> 00:04:35,450
The DAG, we want that to be the DAG that we defined within our subDAG on line 25.

75
00:04:35,510 --> 00:04:39,550
Next, we need to pass in a Postgres connection ID,

76
00:04:39,550 --> 00:04:41,470
but we can't be sure that it's going to be redshift.

77
00:04:41,470 --> 00:04:43,300
Maybe we want to talk to a different cluster

78
00:04:43,300 --> 00:04:45,450
or different database altogether and a subDAG.

79
00:04:45,450 --> 00:04:47,140
We can't make those kinds of assumptions.

80
00:04:47,140 --> 00:04:49,810
So, we need to go up here and grab

81
00:04:49,810 --> 00:04:56,120
the redshift connection ID variable and fill it in for our Postgres connection ID.

82
00:04:56,310 --> 00:05:01,660
Finally and importantly, we don't know what SQL we need to execute.

83
00:05:01,660 --> 00:05:05,520
Who knows what the create_trips SQL might look like.

84
00:05:05,990 --> 00:05:08,345
So, to do that,

85
00:05:08,345 --> 00:05:10,625
we need to grab this create SQL statement,

86
00:05:10,625 --> 00:05:12,840
which we're going to pass in,

87
00:05:12,850 --> 00:05:16,040
and we're going to execute that.

88
00:05:20,260 --> 00:05:23,630
All right. So, now our create_trips_table,

89
00:05:23,630 --> 00:05:26,200
and it really shouldn't have the name trips in it anymore.

90
00:05:26,200 --> 00:05:28,060
So, we call this create_table.

91
00:05:28,060 --> 00:05:33,765
Our create_table task in our subDAG has been fully configured.

92
00:05:33,765 --> 00:05:38,475
Next, we need to look at our copy_trips_task and make this generic.

93
00:05:38,475 --> 00:05:41,030
So, the first thing we're going to do is remove

94
00:05:41,030 --> 00:05:43,700
this trips variable or trips name

95
00:05:43,700 --> 00:05:46,685
from our variable name because now we just want a generic copy task.

96
00:05:46,685 --> 00:05:48,440
Unlike in the previous example,

97
00:05:48,440 --> 00:05:54,475
we're going to use a formatting string and say, load_table from s3_to_redshift.

98
00:05:54,475 --> 00:05:57,470
Here, we're going to delete the trips_table because

99
00:05:57,470 --> 00:06:01,295
the table could be anything now that it's a subDAG that's reusable,

100
00:06:01,295 --> 00:06:07,440
and then we're going to replace the redshift_conn_id with redshift_conn_id.

101
00:06:07,990 --> 00:06:13,715
Again, these variables are coming from our function up here.

102
00:06:13,715 --> 00:06:19,800
Next, we need to fill in the s3 bucket and key and the aws_credentials_id.

103
00:06:21,170 --> 00:06:26,344
So here, we can no longer assume that the aws_credentials is aws_credentials,

104
00:06:26,344 --> 00:06:30,920
so we're going to use our variable aws_credentials_id.

105
00:06:30,920 --> 00:06:34,190
We're going to replace this specific bucket name with

106
00:06:34,190 --> 00:06:38,135
a variable name because the user may want to specify a different bucket.

107
00:06:38,135 --> 00:06:40,820
Finally, it will replace the key with

108
00:06:40,820 --> 00:06:44,990
a different key because the user may want to specify a different key.

109
00:06:44,990 --> 00:06:50,205
Now, at this point, we've defined our S3ToRedshiftOperator in a reusable fashion.

110
00:06:50,205 --> 00:06:53,975
Our subDAG is almost ready to go except we're missing one thing.

111
00:06:53,975 --> 00:06:57,140
We need to define ordering of our tasks.

112
00:06:57,140 --> 00:07:01,690
The create_task must occur before the copy_task.

113
00:07:01,690 --> 00:07:05,550
So, you can see here, I'm going to delete these TO DO's since we've done it.

114
00:07:05,550 --> 00:07:09,950
You can see here we have create_table, we have copy_task.

115
00:07:09,950 --> 00:07:17,160
So, we want to make sure that the create_table occurs before the copy_task.

116
00:07:17,160 --> 00:07:20,270
Now that we've done that, we can actually close this

117
00:07:20,270 --> 00:07:23,970
out because our subDAG should be properly configured.

118
00:07:25,570 --> 00:07:30,530
In here, we should be able to go in and now we can delete some of those code.

119
00:07:30,530 --> 00:07:36,180
We don't need to write this create_trips_table or copy_trips task anymore.

120
00:07:36,830 --> 00:07:43,190
Same with create_stations and copy_stations because we've parameterized or subDAGs above.

121
00:07:43,190 --> 00:07:45,890
So, now we only have check_trips,

122
00:07:45,890 --> 00:07:49,775
and check_stations, and our actual location_traffic_task.

123
00:07:49,775 --> 00:07:53,060
So, you can see down here that we still have to

124
00:07:53,060 --> 00:07:57,620
replace some of the usages of those create and copy_task.

125
00:07:57,620 --> 00:08:02,195
We're going to jump back up above and we're going to look at our SubDagOperator.

126
00:08:02,195 --> 00:08:05,170
So, we've instantiated the SubDagOperator,

127
00:08:05,170 --> 00:08:08,040
we've provided the subDAG function call,

128
00:08:08,040 --> 00:08:10,070
and we've properly parameterized

129
00:08:10,070 --> 00:08:14,030
the subDAG with all of the arguments that it would need to get going.

130
00:08:14,030 --> 00:08:20,370
So, we have a trip_subdag_task and we have a stations_subdag_task.

131
00:08:20,370 --> 00:08:25,300
So, at the bottom here,

132
00:08:25,300 --> 00:08:30,480
we're going to have a trip_subdag_task run before we actually

133
00:08:30,480 --> 00:08:35,280
run our location_traffic_task, excuse me,

134
00:08:35,280 --> 00:08:42,930
before we run our check_traffic_task or check_trips_task,

135
00:08:42,930 --> 00:08:48,160
and then we're going to run our stations_subdag_task

136
00:08:48,260 --> 00:08:52,180
before we run our check_stations_task.

137
00:08:52,790 --> 00:08:57,395
At this point, the create and copy steps can be removed.

138
00:08:57,395 --> 00:09:01,535
We can also remove the copy to check_stations dependencies.

139
00:09:01,535 --> 00:09:05,460
Now, we have a properly configured DAG.

140
00:09:05,710 --> 00:09:09,150
Let's see if Airflow loads the code.

141
00:09:09,700 --> 00:09:14,030
So, it looks like I miss to find something here.

142
00:09:14,030 --> 00:09:19,370
You can tell that if you've broken a DAG or your code isn't properly configured,

143
00:09:19,370 --> 00:09:21,590
Airflow will actually pop up a warning saying,

144
00:09:21,590 --> 00:09:23,220
"Hey, I couldn't parse your code."

145
00:09:23,220 --> 00:09:27,140
So, here it's saying the check_trips_task could not be found so it wasn't defined.

146
00:09:27,140 --> 00:09:30,365
So, let's see if we can see what's going on here.

147
00:09:30,365 --> 00:09:32,480
So, the first thing we notice is that,

148
00:09:32,480 --> 00:09:34,505
here, we have check_trips_task, right?

149
00:09:34,505 --> 00:09:36,085
I've used that variable name.

150
00:09:36,085 --> 00:09:39,360
But on line 55, it's actually defined as check_trips;

151
00:09:39,360 --> 00:09:41,400
same thing with check_stations.

152
00:09:41,400 --> 00:09:43,940
So, neither one of these variables is defined.

153
00:09:43,940 --> 00:09:48,755
So, I'm going to go to line 79, going to delete off the task,

154
00:09:48,755 --> 00:09:52,050
and so now we have properly named variables.

155
00:09:52,050 --> 00:09:56,195
Let's go and reload Airflow and see if it has picked up or changes.

156
00:09:56,195 --> 00:09:58,705
Now, when a DAG breaks,

157
00:09:58,705 --> 00:10:01,890
when you've made a mistake, it can take Airflow a few moments to pick up your changes.

158
00:10:01,890 --> 00:10:06,260
So, we're going to be patient and just give it a few moments here to pick up our changes.

159
00:10:06,260 --> 00:10:09,215
You can see when it fails to load,

160
00:10:09,215 --> 00:10:11,210
that Airflow actually, basically,

161
00:10:11,210 --> 00:10:12,230
black out the names,

162
00:10:12,230 --> 00:10:13,700
so you can't click on it, and it'll put

163
00:10:13,700 --> 00:10:16,610
those little information bubble here that you can hover over saying,

164
00:10:16,610 --> 00:10:19,230
"Hey, the DAG isn't available."

165
00:10:19,900 --> 00:10:23,425
So, we can now see that our error is gone,

166
00:10:23,425 --> 00:10:27,225
and we can see that lesson3.demo3 is now available again.

167
00:10:27,225 --> 00:10:30,180
Airflow is now able to correctly parse our DAG.

168
00:10:30,180 --> 00:10:31,500
So, we're going to look at the code.

169
00:10:31,500 --> 00:10:35,735
We're just going to verify that everything looks correct.

170
00:10:35,735 --> 00:10:39,135
We have our SubDagOperators, stations and trips.

171
00:10:39,135 --> 00:10:40,785
We have our two checks,

172
00:10:40,785 --> 00:10:46,220
a location_traffic_task, and we've reordered to use our subdag_task.

173
00:10:46,220 --> 00:10:48,970
So, let's go ahead and actually run this code.

174
00:10:48,970 --> 00:10:53,610
We go back to this menu, return on lesson3.demo3,

175
00:10:53,610 --> 00:11:00,620
going to click Play, and then we're going to open up a DAG and see that it works.

176
00:11:00,620 --> 00:11:03,890
So first, we're going to jump into our Graph View.

177
00:11:03,890 --> 00:11:06,500
So, you'll notice this looks a little different.

178
00:11:06,500 --> 00:11:09,440
We have a trips_subdag and the stations_subdag,

179
00:11:09,440 --> 00:11:11,510
and we'll see we don't get a lot of information.

180
00:11:11,510 --> 00:11:13,235
If I wanted to see more information,

181
00:11:13,235 --> 00:11:17,740
I could click on the trips_subdag and click Zoom into Sub DAG.

182
00:11:17,740 --> 00:11:19,925
This will show me more information.

183
00:11:19,925 --> 00:11:23,465
I'm going to wait for this to execute so we can get a little farther along.

184
00:11:23,465 --> 00:11:24,800
So, we can see this DAGs,

185
00:11:24,800 --> 00:11:30,280
these two subDAGs are both running now and they both completed.

186
00:11:30,280 --> 00:11:32,600
So, the two checks will know happen,

187
00:11:32,600 --> 00:11:35,210
and then the calculate_location_traffic task will happen.

188
00:11:35,210 --> 00:11:38,270
While they're doing that, let's take a look at our subDAG.

189
00:11:38,270 --> 00:11:40,430
So, before we jump in in the black menu here,

190
00:11:40,430 --> 00:11:43,820
you can see the operator type is SubDagOperator.

191
00:11:43,820 --> 00:11:48,415
If I click on this and then I go to Zoom into Sub DAG,

192
00:11:48,415 --> 00:11:51,800
I can actually see the steps that are part of my subDAG.

193
00:11:51,800 --> 00:11:54,950
So, notice up here, our menu looks a little different.

194
00:11:54,950 --> 00:12:00,430
SUBDAG: lesson3.demo3.trips_subdag.

195
00:12:00,430 --> 00:12:02,960
We can see that here we can actually see

196
00:12:02,960 --> 00:12:06,470
the PostgresOperators and the S3ToRedshiftOperator.

197
00:12:06,470 --> 00:12:08,195
Likewise, in the graph,

198
00:12:08,195 --> 00:12:11,825
we can see just the two tasks that are involved in our subDAG.

199
00:12:11,825 --> 00:12:16,860
I can even click in and see the logs just like I could in the past.

200
00:12:16,960 --> 00:12:19,535
So, let's return to their home menu,

201
00:12:19,535 --> 00:12:22,070
we'll go back to lesson3.demo3,

202
00:12:22,070 --> 00:12:26,220
and you can see there our DAG has now completed successfully.

