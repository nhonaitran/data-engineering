1
00:00:00,000 --> 00:00:03,090
In this demonstration, we're going to look at a DAG that has

2
00:00:03,090 --> 00:00:05,895
a single task with poorly defined boundaries.

3
00:00:05,895 --> 00:00:08,670
We're going to see how we might refactor it into a cleaner,

4
00:00:08,670 --> 00:00:10,860
simpler to understand series of tasks.

5
00:00:10,860 --> 00:00:14,940
So, first, we're going to turn off lesson3.solution1.

6
00:00:14,940 --> 00:00:18,225
We're going to return to the DAG's menu,

7
00:00:18,225 --> 00:00:22,305
and then we're going to open up our demo2.

8
00:00:22,305 --> 00:00:25,755
So, in demo2, we have one giant function.

9
00:00:25,755 --> 00:00:27,900
We have this load_and_analyze function,

10
00:00:27,900 --> 00:00:31,780
which you can see is grabbing our redshift connection,

11
00:00:31,790 --> 00:00:35,025
running some code against redshift,

12
00:00:35,025 --> 00:00:40,130
getting some records from redshift and checking to see what the oldest rider is,

13
00:00:40,130 --> 00:00:43,820
then creating another table in redshift,

14
00:00:43,820 --> 00:00:48,770
and then again checking to see who the youngest rider was.

15
00:00:48,770 --> 00:00:53,105
Then there are even more SQL statements down here.

16
00:00:53,105 --> 00:00:55,530
One is for lifetime_rides.

17
00:00:55,530 --> 00:00:58,275
One is for city_station_counts.

18
00:00:58,275 --> 00:00:59,820
Again, just to reiterate,

19
00:00:59,820 --> 00:01:01,100
this is one function.

20
00:01:01,100 --> 00:01:03,940
We have a single load_and_analyze function here.

21
00:01:03,940 --> 00:01:07,290
So, in this DAG, we have DAG defined here.

22
00:01:07,290 --> 00:01:10,300
We have this load_and_analyze function.

23
00:01:10,700 --> 00:01:13,695
What would happen if something failed?

24
00:01:13,695 --> 00:01:16,680
How would we know what failed and why?

25
00:01:16,680 --> 00:01:20,500
If I were to have run this task, and we got, say,

26
00:01:20,500 --> 00:01:23,785
to this lifetime_rides SQL statement,

27
00:01:23,785 --> 00:01:25,790
and it failed, it wouldn't be immediately

28
00:01:25,790 --> 00:01:28,475
obvious that that was the reason that the DAG had failed.

29
00:01:28,475 --> 00:01:32,795
I'd have to actually open up the logs and read the logs to figure out what was going on.

30
00:01:32,795 --> 00:01:36,770
So, a better way of doing this would be to actually create

31
00:01:36,770 --> 00:01:41,170
PythonOperators and PostgresOperators for each one of these tasks.

32
00:01:41,170 --> 00:01:43,220
So, I'm going to go ahead and get started with this,

33
00:01:43,220 --> 00:01:46,940
and then I'm going to ask you to pick up where I left off to finish the refactor.

34
00:01:46,940 --> 00:01:51,200
So, we'll start by looking at all the separate pieces of functionality in here.

35
00:01:51,200 --> 00:01:53,945
So, we know that our SQL statements can be run

36
00:01:53,945 --> 00:01:57,770
independently from the actual analysis function that we're running.

37
00:01:57,770 --> 00:02:02,330
So, here, we have a redshift_hook that's running a CREATE TABLE.

38
00:02:02,330 --> 00:02:04,370
This could be its own task.

39
00:02:04,370 --> 00:02:06,589
After that task is completed,

40
00:02:06,589 --> 00:02:10,235
then we could actually go ahead and get the records and perform some analysis,

41
00:02:10,235 --> 00:02:12,140
figuring out who the oldest rider was.

42
00:02:12,140 --> 00:02:14,390
So, let's go ahead and give that a shot.

43
00:02:14,390 --> 00:02:16,940
So, I'm going to start by taking this code,

44
00:02:16,940 --> 00:02:19,225
just taking the SQL code,

45
00:02:19,225 --> 00:02:21,585
and copy it to the bottom.

46
00:02:21,585 --> 00:02:29,250
I'm going to make an oldest_rider_ table task.

47
00:02:33,010 --> 00:02:42,180
We're going to give it a task_id, we'll call it oldest_riders_table,

48
00:02:44,270 --> 00:02:47,590
we're going to assign it a DAG,

49
00:02:47,750 --> 00:02:51,820
and we're going to give it a SQL statement.

50
00:02:57,650 --> 00:03:07,160
Then, of course, we also need to tell it postgres_connection_id. All right.

51
00:03:07,160 --> 00:03:10,570
With that, we should be all set to go to actually remove

52
00:03:10,570 --> 00:03:13,980
this from our load_and_analyze task.

53
00:03:13,980 --> 00:03:16,750
So, I'm going to remove this code.

54
00:03:17,300 --> 00:03:21,130
Next, we have this analysis function here,

55
00:03:21,130 --> 00:03:23,050
where we're actually trying to get the birth year of

56
00:03:23,050 --> 00:03:25,720
the oldest rider and then log it out.

57
00:03:25,720 --> 00:03:29,410
So, we're going to make a new function to do that.

58
00:03:29,410 --> 00:03:35,415
So, we're going to say we're going to write an oldest_rider function,

59
00:03:35,415 --> 00:03:42,155
and we're actually just going to copy this code and paste it in here.

60
00:03:42,155 --> 00:03:45,700
So, now we have an oldest writer function.

61
00:03:45,700 --> 00:03:47,635
We've got our redshift_hook.

62
00:03:47,635 --> 00:03:50,350
We're actually selecting the birth year from the oldest_riders.

63
00:03:50,350 --> 00:03:51,625
We're taking those records,

64
00:03:51,625 --> 00:03:53,975
and then we're logging the oldest rider.

65
00:03:53,975 --> 00:03:58,690
So, I'm going to define the new PythonOperator here,

66
00:04:02,900 --> 00:04:11,850
going to give it a task_id, going to assign it a DAG,

67
00:04:11,850 --> 00:04:15,900
I'm going to give it a python_callable,

68
00:04:15,900 --> 00:04:18,970
and I need to check what I named that function.

69
00:04:18,970 --> 00:04:21,910
On line 12, we call it oldest_rider.

70
00:04:21,910 --> 00:04:24,970
So, we'll go to the bottom of our code again,

71
00:04:24,970 --> 00:04:28,455
and then I think that's everything.

72
00:04:28,455 --> 00:04:31,060
We don't need to give it context because we didn't use context.

73
00:04:31,060 --> 00:04:33,470
Let's double-check that real quick.

74
00:04:35,900 --> 00:04:38,505
So, let's take a look.

75
00:04:38,505 --> 00:04:40,065
Did we use context here?

76
00:04:40,065 --> 00:04:41,260
It doesn't look like we did.

77
00:04:41,260 --> 00:04:43,835
So, we don't need to provide context to this function.

78
00:04:43,835 --> 00:04:45,320
If we were to provide context,

79
00:04:45,320 --> 00:04:47,885
we would need to give this args and kwargs.

80
00:04:47,885 --> 00:04:49,785
So, now that we've done that,

81
00:04:49,785 --> 00:04:55,200
we can actually go ahead and delete this code that's been refactored into its own task.

82
00:04:55,880 --> 00:04:59,730
So, one of the things that's really nice about this is now

83
00:04:59,730 --> 00:05:04,650
load_and_analyze can run independently of oldest_riders_table,

84
00:05:06,020 --> 00:05:11,320
and the oldest_riders_table needs to run before we print the oldest_rider.

85
00:05:11,630 --> 00:05:14,390
So, we've gone ahead and save this file.

86
00:05:14,390 --> 00:05:18,960
We've defined task ordering of our two new operators.

87
00:05:19,100 --> 00:05:21,440
Then we're going to go in here, and we're going to

88
00:05:21,440 --> 00:05:24,510
double-check that the code was picked up correctly.

89
00:05:24,650 --> 00:05:29,445
So, you can see we have a log_oldest function here.

90
00:05:29,445 --> 00:05:32,130
Excuse me, I pulled up the solution.

91
00:05:32,130 --> 00:05:33,840
Didn't want to pull that up yet.

92
00:05:33,840 --> 00:05:36,875
So, we're going to come to the main DAG menu.

93
00:05:36,875 --> 00:05:39,295
We're going to look at lesson3.demo2.

94
00:05:39,295 --> 00:05:41,955
We're going to look at the code.

95
00:05:41,955 --> 00:05:46,810
You can see that we have an oldest_rider function.

96
00:05:47,200 --> 00:05:50,540
You can see the code that we define is deleted.

97
00:05:50,540 --> 00:05:52,670
We now only have the younger_riders code,

98
00:05:52,670 --> 00:05:55,160
which you'll work on in your solution.

99
00:05:55,160 --> 00:05:57,350
Then at the bottom here, we have

100
00:05:57,350 --> 00:06:01,585
our older_riders_table task and our print_oldest_rider task,

101
00:06:01,585 --> 00:06:03,570
and those two things line up.

102
00:06:03,570 --> 00:06:06,125
So, we're going to go ahead and give this a shot.

103
00:06:06,125 --> 00:06:07,960
Go back to DAGs,

104
00:06:07,960 --> 00:06:10,710
and we're going to turn on lesson3.demo2.

105
00:06:10,710 --> 00:06:12,700
Now, I didn't assign this a schedule.

106
00:06:12,700 --> 00:06:15,690
So, you need to go ahead and click the Run button.

107
00:06:20,240 --> 00:06:23,355
So, we're going to go back to lesson3.demo2,

108
00:06:23,355 --> 00:06:25,860
and we're going to watch the progression.

109
00:06:31,220 --> 00:06:35,940
All right. So, you can see load_and_analyze is actually running independently,

110
00:06:35,940 --> 00:06:38,510
and this was the big bloated function that we're refactoring,

111
00:06:38,510 --> 00:06:41,720
is running independently from the two tasks that we defined.

112
00:06:41,720 --> 00:06:45,815
Already you can see that we have much, much improved visibility.

113
00:06:45,815 --> 00:06:52,200
We have a better idea of what's happening instead of just this one giant function.

114
00:06:52,220 --> 00:06:55,210
So, our older_riders_table has been created.

115
00:06:55,210 --> 00:06:58,380
So, our PostgresOperator that we created is now complete,

116
00:06:58,380 --> 00:07:02,175
and you can see it completed before the load_and_analyze function completed.

117
00:07:02,175 --> 00:07:06,640
So, you've already seen the benefits of parallelization,

118
00:07:06,640 --> 00:07:09,390
and then we printed the oldest_rider as well.

119
00:07:09,390 --> 00:07:10,620
So, now that's completed.

120
00:07:10,620 --> 00:07:12,890
Again, these two functions were able to

121
00:07:12,890 --> 00:07:15,875
complete while other work was happening in load_and_analyze.

122
00:07:15,875 --> 00:07:21,115
So, let's go see how old our oldest rider was,

123
00:07:21,115 --> 00:07:24,940
and our oldest rider was apparently born in 1900.

