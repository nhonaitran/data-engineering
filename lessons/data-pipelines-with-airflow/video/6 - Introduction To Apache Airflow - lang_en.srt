1
00:00:00,000 --> 00:00:02,835
So now that we're familiar with data pipelines and DAGs,

2
00:00:02,835 --> 00:00:05,099
I'd like to introduce Apache airflow.

3
00:00:05,099 --> 00:00:08,580
Airflow is an open source tool which marries the concepts we've been talking

4
00:00:08,580 --> 00:00:12,089
about into an easy to use and intuitive framework.

5
00:00:12,089 --> 00:00:13,410
So on the screen right now,

6
00:00:13,410 --> 00:00:16,890
you can see a sample of the airflow user interface.

7
00:00:16,890 --> 00:00:19,445
We're going to be talking more about this shortly,

8
00:00:19,445 --> 00:00:22,859
but I just want to give you a bit of a taste of what you're about to see.

9
00:00:22,859 --> 00:00:26,719
So airflow is created at Airbnb with the goal of

10
00:00:26,719 --> 00:00:30,500
organizing their substantial and complicated data pipeline infrastructure,

11
00:00:30,500 --> 00:00:33,710
into one tool that can run in mission critical environments.

12
00:00:33,710 --> 00:00:36,814
Another goal was making sure that teams could understand

13
00:00:36,814 --> 00:00:40,070
at a glance how their pipelines were triggered or scheduled,

14
00:00:40,070 --> 00:00:42,710
and how all of the steps and their DAGs fit together.

15
00:00:42,710 --> 00:00:46,189
Since 2015, airflow has experienced explosive growth,

16
00:00:46,189 --> 00:00:51,594
has been adopted by data engineering teams at some of the biggest names in the industry.

17
00:00:51,594 --> 00:00:55,250
What makes airflow so popular is that it makes writing

18
00:00:55,250 --> 00:00:58,564
and deploying data pipelines simpler than ever before.

19
00:00:58,564 --> 00:01:00,859
Airflow DAGs are written in Python.

20
00:01:00,859 --> 00:01:02,810
A language that is friendly for developers and

21
00:01:02,810 --> 00:01:05,269
used widely by data engineers and their tools.

22
00:01:05,269 --> 00:01:08,179
Additionally, airflow comes out of the box with

23
00:01:08,180 --> 00:01:10,850
integrations for widely used tools like Redshift,

24
00:01:10,849 --> 00:01:13,534
S3, Spark and more.

25
00:01:13,534 --> 00:01:16,549
But integration doesn't exist for a tool you want to work with,

26
00:01:16,549 --> 00:01:18,469
airflow has a simple interface for building

27
00:01:18,469 --> 00:01:21,959
that integration and sharing it with other developers.

28
00:01:22,030 --> 00:01:27,769
Perhaps best of all, airflow makes visualizing your DAGs easier than ever before.

29
00:01:27,769 --> 00:01:29,719
All a developer has to do to create

30
00:01:29,719 --> 00:01:32,914
a visual representation of their DAG is to code it in Python,

31
00:01:32,915 --> 00:01:35,075
and then pull it up in the Airflow UI.

32
00:01:35,075 --> 00:01:37,969
The Airflow UI automatically transforms a DAG you've

33
00:01:37,969 --> 00:01:40,655
written in Python into a DAG visualization.

34
00:01:40,655 --> 00:01:43,409
Complete with the schedule, execution diagrams,

35
00:01:43,409 --> 00:01:47,134
log output, as well as a host of other great features which we're going to cover.

36
00:01:47,135 --> 00:01:48,920
So real quick on this slide,

37
00:01:48,920 --> 00:01:52,040
you can see an example of a DAG over here.

38
00:01:52,040 --> 00:01:53,734
You can see the relationships.

39
00:01:53,734 --> 00:01:55,584
You can see the nodes.

40
00:01:55,584 --> 00:01:57,974
Although it's a little bit blocked here,

41
00:01:57,974 --> 00:02:02,234
on the screenshot you can even see all of the executions.

42
00:02:02,234 --> 00:02:06,034
Each one of these columns is an execution for a particular date.

43
00:02:06,034 --> 00:02:08,210
Don't worry if this isn't perfectly clear right now,

44
00:02:08,210 --> 00:02:11,310
we're going to spend more time in this UI, and it'll get more familiar.

